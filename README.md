# Court Intelligence

Проект посвящён построению модели машинного обучения для решения задачи бинарной классификации исходов спортивных (в данном случае баскетбольных) матчей
Модель в некотором роде сырая и многое можно еще усовершенс твовать, о чем далее, но главную задачу в обучении самого себя, я, кажется, достиг.

## Поставленные цели

Изначально я не рассчитывал получить гениально работающий продукт, я хотел лишь разобраться как работает машинное обучение.
Таким образом я наметил себе цели:

- Изучить R
- Овладеть библиотекой matplotlib 
- Овладеть библиотекой seaborn
- Овладеть библиотекой pandas
- Овладеть библиотекой numpy
- Разобраться в принципах машинного обучения
- Разобраться с Google Collab и Jupiter Notebooks файлами

## Результаты

- Прошел пару курсов на степике, в том числе по R, который мне не пригодился в итоге, но лишним точно не будет
- Моя модель верно предсказывает исход матча на основе имебщей статистики примерно 60% матчей, что, вроде, очень даже неплохо
- К сожаления, у меня так и не получилось интегрировать фичу, которая позволила бы набрать свои команды из имеющихся в базе данных игроков, чтобы предсказать, кто бы выиграл в этом случае.
- Работать в Collab оказалось действительно удобно. Запускать код по частям одной кнопочкой мне понравилось. к тому же, интерактивные окна, где можно смотреть графики, например, тоже добавляют поводов туда возвращаться, днако, при попытке обучить модель для фичи по набору любых игроков в команды, он пожаловался, что я использовал всю имебщуюся память. Возможно, где-то был косяк с кодом, но я так и не разобрался.

## Структура проекта

- https://drive.google.com/drive/folders/19DARAbUwjE72Ly0XpLxEvFB96c4UR8iI?usp=drive_link

это ссылка на всю базу данных, которую я использовал для обучения. При желании, можно скачать файлики и попробовать запустить. Далее я оставлю метрики, которые мне удалось получить
- Если решите запустить, то предварительно нужно установить зависимости
pip install -r requirements.txt
а после все csv файлики с гугл диска нужно поместить в папку *database/csv*

- Кроме того, в папке *plots* присутсвует несколько картинок, которые отражают некоторые метрики, но подробнее их выдает основной код

- *main.py* запускает обучение и вывод метрик

## Ход работы

Изначально модель писалась под XGBoost, но после решил отказаться от этой библиотеки в пользу sklearn-моделей, в частности HistGradientBoostingClassifier. Размер датасета (~40 000 матчей, 70+ признаков) позволяет использовать более простые и стабильные модели, которые хорошо справляются с задачей, быстрее обучаются и проще интегрируются с существующим стеком инструментов (Pipeline, GridSearchCV, метрики sklearn). При этом качество предсказаний сопоставимо с XGBoost, и прирост точности от его использования был бы минимальным.

Большая часть работы ушла на борьбу с переобучением и подготовку данных для модели. Удалил все признаки, которые становятся известны только после матча, например, итоговые очки, подборы, передачи и процент попаданий. А после добавил несколько признаков, отражающих силу команд, например средние статистика за последние 10 матчей, паттерны по четвертям (доля очков в начале и конце игры, разница между половинами), разницу между домашней и выездной командой по ключевым показателям, дни отдыха, серию и прочие.

Проблема с переобучением решилась (по правде она решилась скорее сразу после того, как я убрал данные, которые модель не должна знать заранее) и после этого я начал пытаться улучшить accuracy накидывая еще признаков.

## Итоги модели 

============================================================
РЕЗУЛЬТАТЫ МОДЕЛИ
============================================================
Train Accuracy: 0.6893
Train ROC-AUC:  0.7411

Test Accuracy:  0.6048
Test ROC-AUC:   0.6218

Confusion Matrix (Test):
[[ 943 2575]
 [ 646 3987]]

Classification Report (Test):
              precision    recall  f1-score   support

    Away Win       0.59      0.27      0.37      3518
    Home Win       0.61      0.86      0.71      4633

    accuracy                           0.60      8151
   macro avg       0.60      0.56      0.54      8151
weighted avg       0.60      0.60      0.56      8151

============================================================
TOP-20 ВАЖНЫХ ПРИЗНАКОВ
============================================================
              feature  importance
          diff_streak    0.023200
      diff_fg_pct_avg    0.012661
         diff_tov_avg    0.005962
         diff_reb_avg    0.003877
         tov_home_avg    0.002282
         diff_ast_avg    0.001730
      fg_pct_home_avg    0.001693
       rest_days_away    0.001251
      ft_pct_home_avg    0.001055
      diff_ft_pct_std    0.001006
         ast_home_avg    0.001006
          diff_pct_q4    0.000920
         diff_reb_std    0.000883
           attendance    0.000859
       rest_days_home    0.000761
pct_q1_rolling_away_q    0.000724
      diff_ft_pct_avg    0.000687
         tov_away_avg    0.000638
         stl_away_std    0.000429
pct_q4_rolling_home_q    0.000393

Baseline (всегда предсказываем домашнюю победу): 0.5684
Улучшение над baseline: +0.0364

============================================================
АНАЛИЗ РЕЗУЛЬТАТОВ
============================================================
1. Test Accuracy: 60.48%
   - Модель превосходит baseline на 3.6%

2. ROC-AUC: 0.6218
   - Показывает способность различать победителя
   - Выше 0.6 = модель работает лучше случайности

3. Precision/Recall баланс:
   - Home Win: precision=0.61, recall=0.86
   - Модель хорошо находит домашние победы
   - Away Win: precision=0.59, recall=0.27
   - Хуже предсказывает выездные победы (они реже)

4. Confusion Matrix:
   - Правильно: 4930 из 8151 (60.5%)
   - False Positives (предсказали home win, был away win): 2575
   - False Negatives (предсказали away win, был home win): 646

### Главный вывод
Доволен проделанной работой, модель выдает на 3% результат лучше, чем просто постоянное предсказание победы хозяев, так что она даже немного умная. В целом проект достиг цели: продемонстрировать работу машинного обучения на реальных данных и получить опыт использования инструментов для создания Ml моделей.